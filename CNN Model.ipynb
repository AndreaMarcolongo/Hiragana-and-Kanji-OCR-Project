{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9beeb9a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "import os\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.image as mpimg\n",
    "import matplotlib.pyplot as plt\n",
    "import pathlib\n",
    "import tensorflow_datasets as tfds\n",
    "from sklearn.metrics import f1_score\n",
    "import sklearn\n",
    "import seaborn as sns\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71851825",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change the path to the folder containing the folders train and set\n",
    "%store -r dst_dir\n",
    "datasets_path = dst_dir \n",
    "train_data_path = os.path.join(datasets_path, 'train')\n",
    "test_data_path = os.path.join(datasets_path, 'test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0a63359",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the dataset\n",
    "train_data, val_data = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "    train_data_path, \n",
    "    color_mode='grayscale',\n",
    "    labels = 'inferred',\n",
    "    image_size=(84, 84),\n",
    "    shuffle=True,\n",
    "    validation_split=0.25,\n",
    "    seed=22,\n",
    "    subset='both'\n",
    "\n",
    ")\n",
    "test_data = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "    test_data_path,\n",
    "    color_mode='grayscale',\n",
    "    labels = 'inferred',\n",
    "    image_size=(84, 84),\n",
    "    shuffle=False,\n",
    "    validation_split=None,\n",
    "    seed=22,\n",
    "    subset=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12856324",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, Activation, Flatten, Conv2D, MaxPooling2D, Rescaling\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4eb9acc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_height = 84\n",
    "img_width = 84\n",
    "\n",
    "rescale_layer = Rescaling(1./255, input_shape=(img_height, img_width, 1))\n",
    "\n",
    "@tf.function\n",
    "def rescale_fn(x, y):\n",
    "    return rescale_layer(x), y\n",
    "\n",
    "train_data_rescaled = train_data.map(rescale_fn)\n",
    "val_data_rescaled = val_data.map(rescale_fn)\n",
    "test_data_rescaled = test_data.map(rescale_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "008f092c",
   "metadata": {},
   "outputs": [],
   "source": [
    "filters = 32\n",
    "num_classes = 50\n",
    "dropout_coeff = 0.2\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "# First convolution layer\n",
    "model.add(Conv2D(filters, (3,3), input_shape=(img_height, img_width, 1)))\n",
    "model.add(Activation(\"relu\"))\n",
    "model.add(MaxPooling2D(pool_size = (2,2)))\n",
    "model.add(Dropout(dropout_coeff, input_shape=(39, 39)))\n",
    "\n",
    "# Second convolution layer\n",
    "model.add(Conv2D(filters, (3,3)))\n",
    "model.add(Activation(\"relu\"))\n",
    "model.add(MaxPooling2D(pool_size = (2,2)))\n",
    "model.add(Dropout(dropout_coeff, input_shape=(17, 17)))\n",
    "\n",
    "# Third convolution layer\n",
    "model.add(Conv2D(filters, (3,3)))\n",
    "model.add(Activation(\"relu\"))\n",
    "model.add(MaxPooling2D(pool_size = (2,2)))\n",
    "model.add(Dropout(dropout_coeff, input_shape=(8, 8)))\n",
    "\n",
    "# Fully Connected Layer #1\n",
    "model.add(Flatten())\n",
    "model.add(Dense(64))\n",
    "model.add(Activation(\"tanh\")) #relu\n",
    "\n",
    "# Fully Connected Layer #2\n",
    "model.add(Dense(64))\n",
    "model.add(Activation(\"tanh\")) #relu\n",
    "\n",
    "# Last Fully Connected Layer, 50 Outputs\n",
    "model.add(Dense(num_classes))\n",
    "model.add(Activation(\"softmax\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6cb7b66",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "800ec9fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.keras.optimizers.Adam(learning_rate=0.01)\n",
    "\n",
    "# Compile the Model\n",
    "model.compile(loss = 'sparse_categorical_crossentropy', optimizer = 'Adam', metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f11c212",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 30\n",
    "\n",
    "# ModelCheckpoint callback to save the best parameters\n",
    "checkpoint = ModelCheckpoint(filepath='weights.best.hdf5', \n",
    "                             save_best_only=True, \n",
    "                             monitor='val_loss', \n",
    "                             mode='min', \n",
    "                             save_weights_only=False)\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(train_data_rescaled, \n",
    "                    validation_data=val_data_rescaled, \n",
    "                    epochs=epochs,\n",
    "                    callbacks=[checkpoint])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2870435",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Training and validation loss/accuracy trend\n",
    "epoch_num = list(range(0, epochs))\n",
    "plt.plot(epoch_num, history.history['loss'], label = 'loss')\n",
    "plt.plot(epoch_num, history.history['accuracy'], label = 'accuracy')\n",
    "plt.plot(epoch_num, history.history['val_loss'], label = 'val_loss')\n",
    "plt.plot(epoch_num, history.history['val_accuracy'], label = 'val_accuracy')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c95962e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_weights('weights.best.hdf5')\n",
    "\n",
    "# Predict on the test data\n",
    "prediction = model.predict(test_data_rescaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "568c0791",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate on test data\n",
    "evaluation = model.evaluate(\n",
    "    test_data_rescaled,\n",
    "    batch_size=32,\n",
    "    verbose=0,\n",
    "    sample_weight=None,\n",
    "    steps=None,\n",
    "    callbacks=None,\n",
    "    max_queue_size=10,\n",
    "    workers=1,\n",
    "    use_multiprocessing=False,\n",
    "    return_dict=False,\n",
    ")\n",
    "\n",
    "print('Loss: ', evaluation[0])\n",
    "print('Accuracy: ', evaluation[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e2f730d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# True labels of the test set\n",
    "y_true = np.concatenate([y for x, y in test_data_rescaled], axis=0)\n",
    "# Predicted labels\n",
    "y_pred = tf.argmax(prediction, axis=1).numpy()\n",
    "\n",
    "# Get the true labels for the test data\n",
    "test_labels = np.argmax(y_true)\n",
    "\n",
    "# Calculate precision, recall, and F1 score\n",
    "precision = precision_score(y_true, y_pred, average='micro')\n",
    "recall = recall_score(y_true, y_pred, average='micro')\n",
    "f1 = f1_score(y_true, y_pred, average='micro')\n",
    "\n",
    "print(\"Precision: {:.4f}\".format(precision))\n",
    "print(\"Recall: {:.4f}\".format(recall))\n",
    "print(\"F1 Score: {:.4f}\".format(f1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1718a020",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the confusion matrix\n",
    "conf_matrix = tf.math.confusion_matrix(y_true, y_pred).numpy()\n",
    "\n",
    "# Plot the confusion matrix\n",
    "df_cm = pd.DataFrame(conf_matrix, range(50), range(50)) \n",
    "plt.figure(figsize=(10,7))\n",
    "sns.set(font_scale=0.6) # for label size\n",
    "sns.heatmap(df_cm, annot=True, annot_kws={\"size\": 6}) # font size\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a92bd75",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_prob = [max(vector) for vector in prediction]\n",
    "\n",
    "# Show the confidence for the predictions in the test set\n",
    "plt.plot(range(2000) ,y_prob)\n",
    "plt.title(\"Prediction Confidence\", fontsize=16)\n",
    "plt.xlabel(\"Samples\", fontsize=12)\n",
    "plt.ylabel(\"Probability\", fontsize=12)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea84efda",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the confidence for the predictions in the test set\n",
    "plt.plot(range(2000), y_prob, linewidth=2) # increase linewidth\n",
    "plt.title(\"Prediction Confidence\", fontsize=16) # increase title fontsize\n",
    "plt.xlabel(\"Samples\", fontsize=12) # increase x-axis label fontsize\n",
    "plt.ylabel(\"Probability\", fontsize=12) # increase y-axis label fontsize\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64cf5c72",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_prob = [0.6, 0.7, 0.8, 0.9]\n",
    "for prob in target_prob:\n",
    "    y_low = [val for val in y_prob if val < prob]\n",
    "    print('Prediction with a probability of less than ',prob ,': ', len(y_low), 'on 2000 predictions')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b83a1907",
   "metadata": {},
   "outputs": [],
   "source": [
    "wrong_predictions = []\n",
    "\n",
    "for i in range(len(y_true)):\n",
    "    if y_true[i] != y_pred[i]:\n",
    "        wrong_predictions.append([i, y_true[i], y_pred[i]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddc44420",
   "metadata": {},
   "outputs": [],
   "source": [
    "%store -r label_dict\n",
    "\n",
    "def wrong_prediction(i):  # Prints the i-th wrong predicted image\n",
    "    try:\n",
    "        labels = os.listdir(test_data_path)\n",
    "        image_folder = labels[wrong_predictions[i][0]//40]\n",
    "        image_folder_path = os.path.join(test_data_path, image_folder)\n",
    "        images = os.listdir(image_folder_path)\n",
    "        wrong_image_path = os.path.join(image_folder_path, images[wrong_predictions[i][0]%40])\n",
    "        wrong_image =  mpimg.imread(wrong_image_path)\n",
    "        plt.imshow(wrong_image, cmap = plt.cm.binary)\n",
    "        plt.grid(None)\n",
    "        plt.show()\n",
    "        print('True label:', label_dict[wrong_predictions[i][1]], '        Predicted label:', label_dict[wrong_predictions[i][2]])\n",
    "    except:\n",
    "        print(f\"The directory does not contain {i} files\")\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d5d4eda",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print a wrongly predicted image\n",
    "wrong_prediction(12)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

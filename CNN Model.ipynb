{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9beeb9a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "import os\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pathlib\n",
    "import tensorflow_datasets as tfds\n",
    "from sklearn.metrics import f1_score\n",
    "import sklearn\n",
    "import seaborn as sn\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71851825",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change the path to the folder containing the folders train and set\n",
    "datasets_path = 'C:/Users/andma/OneDrive/Documenti/hiragana images/hiragana_images'\n",
    "train_data_path = os.path.join(datasets_path, 'train')\n",
    "test_data_path = os.path.join(datasets_path, 'test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0a63359",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the dataset\n",
    "train_data, val_data = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "    train_data_path, \n",
    "    color_mode='grayscale',\n",
    "    labels = 'inferred',\n",
    "    image_size=(84, 84),\n",
    "    shuffle=True,\n",
    "    validation_split=0.25,\n",
    "    seed=22,\n",
    "    subset='both'\n",
    "\n",
    ")\n",
    "test_data = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "    test_data_path,\n",
    "    color_mode='grayscale',\n",
    "    labels = 'inferred',\n",
    "    image_size=(84, 84),\n",
    "    shuffle=False,\n",
    "    validation_split=None,\n",
    "    seed=22,\n",
    "    subset=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12856324",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, Activation, Flatten, Conv2D, MaxPooling2D, Rescaling\n",
    "from tensorflow.keras import regularizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4eb9acc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_height = 84\n",
    "img_width = 84\n",
    "\n",
    "rescale_layer = Rescaling(1./255, input_shape=(img_height, img_width, 1))\n",
    "\n",
    "# Create a new dataset by applying the rescaling layer to the tdataset\n",
    "train_data_rescaled = train_data.map(lambda x, y: (rescale_layer(x), y))\n",
    "val_data_rescaled = val_data.map(lambda x, y: (rescale_layer(x), y))\n",
    "test_data_rescaled = test_data.map(lambda x, y: (rescale_layer(x), y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "008f092c",
   "metadata": {},
   "outputs": [],
   "source": [
    "filters = 32\n",
    "num_classes = 50\n",
    "dropout_coeff = 0.2\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "# First convolution layer\n",
    "model.add(Conv2D(filters, (3,3), input_shape=(img_height, img_width, 1)))\n",
    "model.add(Activation(\"relu\"))\n",
    "model.add(MaxPooling2D(pool_size = (2,2)))\n",
    "model.add(Dropout(dropout_coeff, input_shape=(39, 39)))\n",
    "\n",
    "# Second convolution layer\n",
    "model.add(Conv2D(filters, (3,3)))\n",
    "model.add(Activation(\"relu\"))\n",
    "model.add(MaxPooling2D(pool_size = (2,2)))\n",
    "model.add(Dropout(dropout_coeff, input_shape=(17, 17)))\n",
    "\n",
    "# Third convolution layer\n",
    "model.add(Conv2D(filters, (3,3)))\n",
    "model.add(Activation(\"relu\"))\n",
    "model.add(MaxPooling2D(pool_size = (2,2)))\n",
    "model.add(Dropout(dropout_coeff, input_shape=(8, 8)))\n",
    "\n",
    "# Fully Connected Layer #1\n",
    "model.add(Flatten())\n",
    "model.add(Dense(64))\n",
    "model.add(Activation(\"tanh\")) #relu\n",
    "\n",
    "# Fully Connected Layer #2\n",
    "model.add(Dense(64))\n",
    "model.add(Activation(\"tanh\")) #relu\n",
    "\n",
    "# Last Fully Connected Layer, 50 Outputs\n",
    "model.add(Dense(num_classes))\n",
    "model.add(Activation(\"softmax\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6cb7b66",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "800ec9fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.keras.optimizers.Adam(learning_rate=0.01)\n",
    "\n",
    "# Compile the Model\n",
    "model.compile(loss = 'sparse_categorical_crossentropy', optimizer = 'Adam', metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f11c212",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Traing with the second splitting of the dataset\n",
    "epochs = 30\n",
    "\n",
    "# Create a ModelCheckpoint callback\n",
    "checkpoint = ModelCheckpoint(filepath='weights.best.hdf5', \n",
    "                             save_best_only=True, \n",
    "                             monitor='val_loss', \n",
    "                             mode='min', \n",
    "                             save_weights_only=False)\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(train_data_rescaled, \n",
    "                    validation_data=val_data_rescaled, \n",
    "                    epochs=epochs,\n",
    "                    callbacks=[checkpoint])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2870435",
   "metadata": {},
   "outputs": [],
   "source": [
    "epoch_num = list(range(0, epochs))\n",
    "plt.plot(epoch_num, history.history['loss'], label = 'loss')\n",
    "plt.plot(epoch_num, history.history['accuracy'], label = 'accuracy')\n",
    "plt.plot(epoch_num, history.history['val_loss'], label = 'val_loss')\n",
    "plt.plot(epoch_num, history.history['val_accuracy'], label = 'val_accuracy')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c95962e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_weights('weights.best.hdf5')\n",
    "\n",
    "# Predict on the test data\n",
    "prediction = model.predict(test_data_rescaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e2f730d",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true = np.concatenate([y for x, y in test_data_rescaled], axis=0)\n",
    "y_pred = tf.argmax(prediction, axis=1).numpy()\n",
    "\n",
    "# Convert the predictions to one-hot encoded labels\n",
    "prediction_labels = np.argmax(prediction, axis=1)\n",
    "\n",
    "# Get the true labels for the test data\n",
    "test_labels = np.argmax(y_true)\n",
    "\n",
    "# Calculate precision, recall, and F1 score\n",
    "precision = precision_score(y_true, prediction_labels, average='micro')\n",
    "recall = recall_score(y_true, prediction_labels, average='micro')\n",
    "f1 = f1_score(y_true, prediction_labels, average='micro')\n",
    "\n",
    "# Print the results\n",
    "print(\"Precision: {:.4f}\".format(precision))\n",
    "print(\"Recall: {:.4f}\".format(recall))\n",
    "print(\"F1 Score: {:.4f}\".format(f1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1718a020",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the confusion matrix\n",
    "conf_matrix = tf.math.confusion_matrix(y_true, y_pred).numpy()\n",
    "\n",
    "# Plot the confusion matrix\n",
    "df_cm = pd.DataFrame(conf_matrix, range(50), range(50)) #range(50)\n",
    "plt.figure(figsize=(10,7))\n",
    "sn.set(font_scale=0.6) # for label size\n",
    "sn.heatmap(df_cm, annot=True, annot_kws={\"size\": 6}) # font size\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "568c0791",
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluation = model.evaluate(\n",
    "    test_data_rescaled,\n",
    "    batch_size=32,\n",
    "    verbose='auto',\n",
    "    sample_weight=None,\n",
    "    steps=None,\n",
    "    callbacks=None,\n",
    "    max_queue_size=10,\n",
    "    workers=1,\n",
    "    use_multiprocessing=False,\n",
    "    return_dict=False,\n",
    ")\n",
    "\n",
    "evaluation"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

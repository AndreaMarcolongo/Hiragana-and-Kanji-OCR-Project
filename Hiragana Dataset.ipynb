{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "429d053d",
   "metadata": {},
   "source": [
    "### Lo scopo di questo codice è prendere il dataset iniziale e trasformarlo tramite metodi di data augmentation in modo da migliorare le prestazioni della CNN.\n",
    "\n",
    "### Caratteristiche del dataset iniziale: 1000 immagini di risoluzione 83x84.\n",
    "### Caratteristiche del dataset finale: 1000 x (n+1) (n è un dato come argomento della funzione perform_augmentation) immagini di risoluzione 84x84 divise in 50 classi per il train/validation dataset, 1000 immagini di risoluzione 84x84 divise in 50 classi per il test dataset\n",
    "\n",
    "### Alle immagini iniziali èstato aggiunto un padding di un pixel (nero) in modo da ottenere la risoluzione di 84x84. Per vedere le augmentations applicate guardare la pipeline. \n",
    "\n",
    "### Anche le immagini iniziali sono contenute in questo dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3c429ee3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from matplotlib import pyplot as plt\n",
    "from PIL import Image, ImageEnhance, ImageOps, ImageChops, ImageDraw, ImageFilter, ImageTransform\n",
    "import albumentations as A\n",
    "import random\n",
    "import shutil\n",
    "import numpy as np\n",
    "import cv2\n",
    "import glob\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "40a5401d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the source and destination directories\n",
    "src_dir = r\"C:\\Users\\andma\\OneDrive\\Documenti\\hiragana images\\hiragana_images_original\\hiragana_images\"\n",
    "dst_dir = r\"C:\\Users\\andma\\OneDrive\\Documenti\\hiragana images\\hiragana_images\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "68cf7aa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create the folders for the training/validation and test dataset if they don't already exist\n",
    "train_data_dir = os.path.join(dst_dir, 'train')\n",
    "test_data_dir = os.path.join(dst_dir, 'test')\n",
    "os.makedirs(train_data_dir, exist_ok=True)\n",
    "os.makedirs(test_data_dir, exist_ok=True)\n",
    "\n",
    "#Create the classes folders if they don't already exist\n",
    "for data_path in [train_data_dir, test_data_dir]:\n",
    "    \n",
    "    for file in os.listdir(src_dir):\n",
    "        src_file = os.path.join(src_dir, file)\n",
    "        name = \"\"\n",
    "        for i in range(4, 7):\n",
    "            if file[i].isdigit() == False:\n",
    "                name = name + file[i]\n",
    "        dst_folder_name = name  # get the letters after \"kana\"\n",
    "        dst_folder = os.path.join(data_path, dst_folder_name)\n",
    "        os.makedirs(dst_folder, exist_ok=True)\n",
    "\n",
    "    # Delete all the images in the folders contained in dst_dir\n",
    "    for folder in os.listdir(data_path):\n",
    "        folder_path = os.path.join(data_path, folder)\n",
    "        for file in os.listdir(folder_path):\n",
    "            file_path = os.path.join(folder_path, file)\n",
    "            os.remove(file_path)\n",
    "\n",
    "# Copy all the images from src_dir to train_data_dir\n",
    "for file in os.listdir(src_dir):\n",
    "    src_file = os.path.join(src_dir, file)\n",
    "    name = \"\"\n",
    "    for i in range(4, 7):\n",
    "        if file[i].isdigit() == False:\n",
    "            name = name + file[i]\n",
    "    dst_folder_name = name  # get the letters after \"kana\"\n",
    "    dst_folder = os.path.join(train_data_dir, dst_folder_name)\n",
    "    dst_file = os.path.join(dst_folder, file)\n",
    "    shutil.copy(src_file, dst_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "56b76452",
   "metadata": {},
   "outputs": [],
   "source": [
    "def augment_image(image):\n",
    "    # Define data augmentation parameters\n",
    "    angle = np.random.uniform(-10, 10)\n",
    "    trans = {'x' : int(np.random.uniform(-10, 10)),  'y' : int(np.random.uniform(-8, 8))}\n",
    "   \n",
    "    # Define the sequence of augmentations\n",
    "    aug = A.Compose([\n",
    "        A.PadIfNeeded (min_height=84, min_width=84, border_mode=0, value=0, always_apply=True),\n",
    "        A.Affine(translate_px=trans,rotate=angle, p=0.5),\n",
    "        A.GaussianBlur(blur_limit = [3, 7], sigma_limit = 0, p=0.5),\n",
    "        #A.GridDistortion(),\n",
    "        #A.Emboss(),\n",
    "        A.Downscale(scale_min=0.6, scale_max=0.9,interpolation={'downscale':cv2.INTER_CUBIC, 'upscale':cv2.INTER_CUBIC}, p=0.2),\n",
    "        A.CoarseDropout(max_holes=8,\n",
    "                        max_height=8,\n",
    "                        max_width=8, \n",
    "                        min_holes=2,\n",
    "                        min_height=3,\n",
    "                        min_width=3,\n",
    "                        p=0.1),\n",
    "        A.OpticalDistortion(distort_limit=0.05,\n",
    "                            shift_limit=0.05,\n",
    "                            interpolation=1,\n",
    "                            border_mode=4,\n",
    "                            p=0.3)\n",
    "    ])\n",
    "    \n",
    "    # Apply the augmentations\n",
    "    augmented_image = aug(image=image)['image']\n",
    "   \n",
    "    # Return the augmented image\n",
    "    return augmented_image\n",
    "\n",
    "def perform_augmentation(dir,subdir_train, subdir_test, file, n):\n",
    "    # Load the image\n",
    "    image = cv2.imread(os.path.join(subdir_train, file))\n",
    "    for i in range(0,n):\n",
    "        # Perform data augmentation\n",
    "        augmented_image = augment_image(image)\n",
    "\n",
    "        # Save augmented image with a different name\n",
    "        new_file_name = file.split(\".\")[0] + \"_aug\" + str(i+1) + \".jpg\"\n",
    "        cv2.imwrite(os.path.join(subdir_train, new_file_name), augmented_image)\n",
    "     \n",
    "    # Perform data augmentation\n",
    "    augmented_image = augment_image(image)\n",
    "\n",
    "    # Save augmented image with a different name\n",
    "    new_file_name = file.split(\".\")[0] + \"_aug_test\" + \".jpg\"\n",
    "    cv2.imwrite(os.path.join(subdir_test, new_file_name), augmented_image)\n",
    "    \n",
    "def add_padding(image, path):\n",
    "    transform = A.PadIfNeeded(min_height=84, min_width=84, border_mode=0, value=0, always_apply=True)\n",
    "    transformed_image = transform(image=np.array(image))['image']\n",
    "    transformed_image = Image.fromarray(transformed_image)\n",
    "    transformed_image.save(os.path.basename(file_path))\n",
    "\n",
    "# Iterate through all subdirectories and image files\n",
    "for subdir, dirs, files in os.walk(train_data_dir):\n",
    "    subdir_test = os.path.join(test_data_dir, os.path.basename(subdir))\n",
    "    for file in files:\n",
    "        file_path = os.path.join(subdir, file)\n",
    "        image = cv2.imread(file_path)\n",
    "        \n",
    "        # Add padding and perform augmentation\n",
    "        add_padding(image, file_path)\n",
    "        perform_augmentation(dirs,subdir,subdir_test, file, 9)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

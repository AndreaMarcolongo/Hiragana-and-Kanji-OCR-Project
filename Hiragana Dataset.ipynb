{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "429d053d",
   "metadata": {},
   "source": [
    "### Lo scopo di questo codice è prendere il dataset iniziale e trasformarlo tramite metodi di data augmentation in modo da migliorare le prestazioni della CNN.\n",
    "\n",
    "### Caratteristiche del dataset iniziale: 1000 immagini di risoluzione 83x84.\n",
    "### Caratteristiche del dataset finale: 1000 x (n+1) (n è un dato come argomento della funzione perform_augmentation) immagini di risoluzione 84x84 divise in 50 classi.\n",
    "\n",
    "### Alle immagini iniziali èstato aggiunto un padding di un pixel (nero) in modo da ottenere la risoluzione di 84x84. Successivamente sono stati applicati casualmente una rotazione tra i -20 e i 20 gradi, un blur con random blur factor tra 0 e 0.1. \n",
    "\n",
    "### Anche le immagini iniziali sono contenute in questo dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3c429ee3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from matplotlib import pyplot as plt\n",
    "from PIL import Image, ImageEnhance, ImageOps, ImageChops, ImageDraw, ImageFilter, ImageTransform\n",
    "import albumentations as A\n",
    "import random\n",
    "import shutil\n",
    "import numpy as np\n",
    "import cv2\n",
    "import glob\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "40a5401d",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Source of the hiragana images\n",
    "destination = Path('C:/Users/andma/OneDrive/Documenti/hiragana images/hiragana_images')\n",
    "# Set the source and destination directories\n",
    "src_dir = r\"C:\\Users\\andma\\OneDrive\\Documenti\\hiragana images\\hiragana_images_original\\hiragana_images\"\n",
    "dst_dir = r\"C:\\Users\\andma\\OneDrive\\Documenti\\hiragana images\\hiragana_images\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "68cf7aa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create the classes folders if they don't already exist\n",
    "for file in os.listdir(src_dir):\n",
    "    src_file = os.path.join(src_dir, file)\n",
    "    name = \"\"\n",
    "    for i in range(4, 7):\n",
    "        if file[i].isdigit() == False:\n",
    "            name = name + file[i]\n",
    "    dst_folder_name = name  # get the letters after \"kana\"\n",
    "    dst_folder = os.path.join(dst_dir, dst_folder_name)\n",
    "    os.makedirs(dst_folder, exist_ok=True)\n",
    "\n",
    "# Delete all the images in the folders contained in dst_dir\n",
    "for folder in os.listdir(dst_dir):\n",
    "    folder_path = os.path.join(dst_dir, folder)\n",
    "    for file in os.listdir(folder_path):\n",
    "        file_path = os.path.join(folder_path, file)\n",
    "        os.remove(file_path)\n",
    "\n",
    "# Copy all the images from src_dir to dst_dir\n",
    "for file in os.listdir(src_dir):\n",
    "    src_file = os.path.join(src_dir, file)\n",
    "    name = \"\"\n",
    "    for i in range(4, 7):\n",
    "        if file[i].isdigit() == False:\n",
    "            name = name + file[i]\n",
    "    dst_folder_name = name  # get the letters after \"kana\"\n",
    "    dst_folder = os.path.join(dst_dir, dst_folder_name)\n",
    "    dst_file = os.path.join(dst_folder, file)\n",
    "    shutil.copy(src_file, dst_folder)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a68ccc2f",
   "metadata": {},
   "source": [
    "### Codice scritto da me in precedenza (le 2 celle sotto)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b9d7c9e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtain the complete paths for all source images\n",
    "subdirect = [x for x in destination.iterdir() if x.is_dir()]\n",
    "\n",
    "subdirect_string = [str(path) for path in subdirect]\n",
    "\n",
    "source_images = [glob.glob(path + '/*.jpg') for path in subdirect_string]\n",
    "\n",
    "images_path = []\n",
    "for lists in source_images:\n",
    "    for path in lists:\n",
    "        images_path.append(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "46bbe55b",
   "metadata": {},
   "outputs": [],
   "source": [
    "subdirect = [x for x in destination.iterdir() if x.is_dir()]\n",
    "\n",
    "subdirect_string = [str(path) for path in subdirect]\n",
    "\n",
    "for subfolder in subdirect_string:\n",
    "    \n",
    "    source_images = [glob.glob(subfolder + '/*.jpg')]  \n",
    "    images_path = []\n",
    "    for lists in source_images:\n",
    "        for path in lists:\n",
    "            images_path.append(path)\n",
    "        \n",
    "    for image in images_path:\n",
    "        \n",
    "        kana = cv2.imread(image) \n",
    "    \n",
    "        # Add 1 pixel padding to the bottom of the images to obtain 84x84 pixels images\n",
    "        padded_image = cv2.copyMakeBorder(kana, 0, 0, 1, 0, cv2.BORDER_CONSTANT)\n",
    "        \n",
    "        cv2.imwrite(image,padded_image) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "56b76452",
   "metadata": {},
   "outputs": [],
   "source": [
    "def augment_image(image):\n",
    "    # Define data augmentation parameters\n",
    "    angle = np.random.uniform(-20, 20)\n",
    "    trans = {'x' : int(np.random.uniform(-10, 10)),  'y' : int(np.random.uniform(-8, 8))}\n",
    "   \n",
    "    # Define the sequence of augmentations\n",
    "    aug = A.Compose([\n",
    "        A.Affine(translate_px=trans,rotate=angle, p=1),\n",
    "        A.GaussianBlur(blur_limit = [3, 5], sigma_limit = 0, always_apply=True)\n",
    "    ])\n",
    "    \n",
    "    # Apply the augmentations\n",
    "    augmented_image = aug(image=image)['image']\n",
    "   \n",
    "    # Return the augmented image\n",
    "    return augmented_image\n",
    "\n",
    "def perform_augmentation(dir,subdir,file, n):\n",
    "    # Load the image\n",
    "    image = cv2.imread(os.path.join(subdir, file))\n",
    "    for i in range(0,n):\n",
    "        # Perform data augmentation\n",
    "        augmented_image = augment_image(image)\n",
    "\n",
    "        # Save augmented image with a different name\n",
    "        new_file_name = file.split(\".\")[0] + \"_aug\" + str(i+1) + \".jpg\"\n",
    "        cv2.imwrite(os.path.join(subdir, new_file_name), augmented_image)\n",
    "\n",
    "# Iterate through all subdirectories and image files\n",
    "for subdir, dirs, files in os.walk(dst_dir):\n",
    "    for file in files:\n",
    "        file_path = os.path.join(subdir, file)\n",
    "        image = cv2.imread(file_path)\n",
    "        \n",
    "        # provide the directory and subdirectory where the images exist and the file name\n",
    "        perform_augmentation(dirs,subdir,file, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "026486d6",
   "metadata": {},
   "source": [
    "#### Tranne per le due celle che ho segnalato prima che sono state scritte interamente da me (e si vede aggiungerei), per le altre mi sono fatto aiutare da ChatGPT e poi io ho aggiunto le necessarie modifiche."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
